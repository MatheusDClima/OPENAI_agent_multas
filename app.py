import os
from dotenv import load_dotenv
import streamlit as st
import sqlite3

from decouple import config

from langchain_google_genai import ChatGoogleGenerativeAI


from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor
from langchain.prompts import PromptTemplate
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_community.agent_toolkits.sql.toolkit  import SQLDatabaseToolkit
from langchain.memory import ConversationBufferMemory
# from langchain_openai import ChatOpenAI
# from langchain.chat_models import ChatOpenAI



load_dotenv()
# Tenta pegar do st.secrets (nuvem) ou do ambiente (.env local)
google_api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))


if not google_api_key:
    raise ValueError("GOOGLE_API_KEY n√£o foi encontrado. Verifique seu .env")


st.set_page_config(
    page_title='Autua√ß√µes GPT',
    page_icon='img/logo.png',
)
st.header('Assistente Autua√ß√µes Pioneira ü§ñ')

model_options = [
    'gemini-1.5-flash',
    'gemini-1.5-pro'
]

st.sidebar.image("img/logo.png", width=100)

selected_model = st.sidebar.selectbox(
    label = 'Selecione o modelo LLM',
    options = model_options
)

st.sidebar.markdown('### Sobre')
st.sidebar.markdown('Este agente consulta o banco de dados das Autua√ß√µes utilizando um modelo GPT.')

st.write('Pe√ßa um relat√≥rio completo ou fa√ßa perguntas sobre as multas, como valor mensal, anual ou em rela√ß√£o ao ano anterior.')
user_question = st.text_input('O que deseja saber?')

# CRIA√á√ÉO DO AGENTE
model = ChatGoogleGenerativeAI(
    model=selected_model,
    google_api_key=google_api_key,
    temperature=0
)

# CONEX√ÉO COM O BANCO
db = SQLDatabase.from_uri('sqlite:///autuacoes.db')
toolkit = SQLDatabaseToolkit(
    db = db,
    llm = model
)
system_message = hub.pull('hwchase17/react')



# CRIANDO AGENTE
agent = create_react_agent(
    llm = model,
    tools = toolkit.get_tools(),
    prompt = system_message
)

# CRIANDO AGENTE EXECUTOR
agent_executor = AgentExecutor(
    agent = agent,
    tools = toolkit.get_tools(),
    verbose = True
)

# PROMPT
prompt = '''
    Voc√™ √© um assistente Analista de Dados especializado nas informa√ß√µes presentes
    no banco de dados que s√£o multas da Via√ß√£o Pioneira.
    Use as ferramentas necess√°rias para responder perguntas sobre as multas presentes no Banco de Dados.
    Forne√ßa insights sobre quantidade, valores, compara√ß√£o com ano/m√™s anterior
    e relat√≥rios conforme solicitado. Sempre responda em portugu√™s brasileiro.
    resposta: {q}
'''
prompt_template = PromptTemplate.from_template(prompt)

# CONDI√á√ÉO DO BOT√ÉO
if st.button('Consultar'):
    if user_question:
        with st.spinner('Consultando o Banco de Dados...'):
            formatted_prompt = prompt_template.format(q=user_question)
            output = agent_executor.invoke({'input': formatted_prompt})
            resposta = output.get("output", "N√£o foi poss√≠vel gerar uma resposta.")
            st.markdown(resposta)
    else:
        st.warning('Por favor, insira uma pergunta.')


# memory = ConversationBufferMemory(
#     memory_key="chat_history",
#     return_messages=True,  # mant√©m como lista de mensagens
#     k=5  # mant√©m apenas as √∫ltimas 5 mensagens
# )
