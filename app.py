import os
from dotenv import load_dotenv
import streamlit as st

from decouple import config

from langchain import hub
from langchain.agents import create_react_agent, AgentExecutor
from langchain.prompts import PromptTemplate
from langchain_community.utilities.sql_database import SQLDatabase
from langchain_community.agent_toolkits.sql.toolkit  import SQLDatabaseToolkit
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
# from langchain.chat_models import ChatOpenAI


load_dotenv()  # carrega as vari√°veis do .env automaticamente

# Agora a chave j√° est√° no ambiente, basta pegar
openai_api_key = os.getenv("OPENAI_API_KEY")


st.set_page_config(
    page_title='Autua√ß√µes GPT',
    page_icon='img/logo.png',
)
st.header('Assistente Autua√ß√µes Pioneira ü§ñ')

model_options = [
    'gpt-3.5-turbo',
    'gpt-4',
    'gpt-4-turbo',
    'gpt-4o-mini',
    'gpt-4o'
]

st.sidebar.image("img/logo.png", width=100)

selected_model = st.sidebar.selectbox(
    label = 'Selecione o modelo LLM',
    options = model_options
)

st.sidebar.markdown('### Sobre')
st.sidebar.markdown('Este agente consulta o banco de dados das Autua√ß√µes utilizando um modelo GPT.')

st.write('Pe√ßa um relat√≥rio completo ou fa√ßa perguntas sobre as multas, como valor mensal, anual ou em rela√ß√£o ao ano anterior.')
user_question = st.text_input('O que deseja saber?')

# CRIA√á√ÉO DO AGENTE
model = ChatOpenAI(
    model = selected_model,
    openai_api_key = openai_api_key,
    max_retries=5,   # tenta novamente se der RateLimit ou erro de rede
    temperature=0    # opcional: mais previs√≠vel p/ queries SQL
)

# CONEX√ÉO COM O BANCO
db = SQLDatabase.from_uri('sqlite:///autuacoes.db')
toolkit = SQLDatabaseToolkit(
    db = db,
    llm = model
)
system_message = hub.pull('hwchase17/react')

# CRIANDO AGENTE
agent = create_react_agent(
    llm = model,
    tools = toolkit.get_tools(),
    prompt = system_message
)

# CRIANDO AGENTE EXECUTOR
agent_executor = AgentExecutor(
    agent = agent,
    tools = toolkit.get_tools(),
    verbose = True
)

# PROMPT
prompt = '''
    Voc√™ √© um assistente especializado em autua√ß√µes da Via√ß√£o Pioneira.
    Use as ferramentas necess√°rias para responder perguntas sobre multas.
    Forne√ßa insights sobre quantidade, valores, compara√ß√£o com ano/m√™s anterior
    e relat√≥rios conforme solicitado. Sempre responda em portugu√™s brasileiro.
    resposta: {q}
'''
prompt_template = PromptTemplate.from_template(prompt)

# CONDI√á√ÉO DO BOT√ÉO
if st.button('Consultar'):
    if user_question:
        with st.spinner('Consultando o Banco de Dados...'):
            formatted_prompt = prompt_template.format(q=user_question)
            output = agent_executor.invoke({'input': formatted_prompt})
            resposta = output.get("output", "N√£o foi poss√≠vel gerar uma resposta.")
            st.markdown(resposta)
    else:
        st.warning('Por favor, insira uma pergunta.')


memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,  # mant√©m como lista de mensagens
    k=5  # mant√©m apenas as √∫ltimas 5 mensagens
)
